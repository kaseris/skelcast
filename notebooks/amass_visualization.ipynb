{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with the AMASS dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from human_body_prior.tools.omni_tools import copy2cpu as c2c\n",
    "\n",
    "support_dir = '/home/kaseris/Documents/amass/support_data'\n",
    "comp_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_680365/1067486171.py:4: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  subject_gender = bdata['gender'].tostring().decode('utf-8')\n"
     ]
    }
   ],
   "source": [
    "amass_npz_fname = osp.join(support_dir, 'github_data/dmpl_sample.npz')\n",
    "bdata = np.load(amass_npz_fname)\n",
    "\n",
    "subject_gender = bdata['gender'].tostring().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what's inside the bdata\n",
    "\n",
    "- What are the `dmpls`? Some body parameters????\n",
    "- What are the `betas`? Body parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available keys from the read file are: ['poses', 'gender', 'mocap_framerate', 'betas', 'marker_data', 'dmpls', 'marker_labels', 'trans']\n",
      "betas: (16,)\n",
      "dmpls: (235, 8)\n",
      "The subject gender is: female\n"
     ]
    }
   ],
   "source": [
    "print(f'The available keys from the read file are: {list(bdata.keys())}')\n",
    "print(f'betas: {bdata[\"betas\"].shape}')\n",
    "print(f'dmpls: {bdata[\"dmpls\"].shape}')\n",
    "print(f'The subject gender is: {subject_gender}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_body_prior.body_model.body_model import BodyModel\n",
    "\n",
    "dmpl_fname = osp.join(support_dir, f'body_models/dmpls/{subject_gender}/model.npz')\n",
    "bm_fname = osp.join(support_dir, f'body_models/smplh/{subject_gender}/model.npz')\n",
    "\n",
    "num_betas = 16 # number of body parameters\n",
    "num_dmpls = 8 # number of DMPL parameters\n",
    "\n",
    "bm = BodyModel(bm_fname=bm_fname, num_betas=num_betas, num_dmpls=num_dmpls, dmpl_fname=dmpl_fname).to(comp_device)\n",
    "faces = c2c(bm.f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided sample data has the original mocap marker data.\n",
    "\n",
    "In the real AMASS dataset, we include only markers for the test set.\n",
    "\n",
    "For the rest of the subsets you can obtain the marker data from their respective websites.\n",
    "\n",
    "In the following we make PyTorch tensors for parameters controlling different part of the body model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Body parameter vector shapes: \n",
      "root_orient: torch.Size([235, 3]) \n",
      "pose_body: torch.Size([235, 63]) \n",
      "pose_hand: torch.Size([235, 90]) \n",
      "trans: torch.Size([235, 3]) \n",
      "betas: torch.Size([235, 16]) \n",
      "dmpls: torch.Size([235, 8])\n",
      "time_length = 235\n"
     ]
    }
   ],
   "source": [
    "time_length = len(bdata['trans'])\n",
    "body_parms = {\n",
    "    'root_orient': torch.Tensor(bdata['poses'][:, :3]).to(comp_device), # controls the global root orientation\n",
    "    'pose_body': torch.Tensor(bdata['poses'][:, 3:66]).to(comp_device), # controls the body\n",
    "    'pose_hand': torch.Tensor(bdata['poses'][:, 66:]).to(comp_device), # controls the finger articulation\n",
    "    'trans': torch.Tensor(bdata['trans']).to(comp_device), # controls the global body position\n",
    "    'betas': torch.Tensor(np.repeat(bdata['betas'][:num_betas][np.newaxis], repeats=time_length, axis=0)).to(comp_device), # controls the body shape. Body shape is static\n",
    "    'dmpls': torch.Tensor(bdata['dmpls'][:, :num_dmpls]).to(comp_device) # controls soft tissue dynamics\n",
    "}\n",
    "print('Body parameter vector shapes: \\n{}'.format(' \\n'.join(['{}: {}'.format(k,v.shape) for k,v in body_parms.items()])))\n",
    "print('time_length = {}'.format(time_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
